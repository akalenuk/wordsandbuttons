<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <title>Outperforming everything with anything</title>
    <meta name="description" content="A 100 lines of Python code that substitute the compiler front-end for a specific computation. This shows that you don't need a “fast” compiling language to write efficient code. In fact, a compilation is only one of the multiple ways to achieve speed.">
    <meta name="keywords" content="programming, performance, show-and-tell">
    <link rel="shortcut icon" type="image/x-icon" href="favicon.ico" />
    <style>
body{
    margin: 0 0 0 0;
}

a{
    text-decoration: none;
}

h1 {
    padding-top: 36pt;
    font-size: 24pt;
    width: 600pt;
    text-align: left;
}

h2 {
    padding-top: 20pt;
    font-size: 20pt;
    width: 555pt;
    text-align: left;
}

p {
    line-height: 1.42;
    font-size: 16pt;
    width: 505pt;
    text-align: left;
}

table.footer {
    padding: 64pt 0pt 32pt 0pt;
    background-color: transparent;
    width: 505pt;
}

td.footer {
    font-family: sans-serif;
    font-size: 16pt;
    font-style: normal;
    padding: 0;
    margin: 0;
    border: 0;
}

pre {
    margin: 0 0 0 0;
    padding-top: 12pt;
    padding-left: 12pt;
    padding-right: 12pt;
    padding-bottom: 12pt;
    font-size: 12pt;
    text-align: left;
    width: 300pt;
}

table {
    border-width: 0pt;
}

td {
    vertical-align: top;
    padding: 6pt 12pt 6pt 12pt;
    font-size: 16pt;
    border: 1px solid black;
    width: 505pt;
}

button{
    width: 248pt;
    height: 42pt;
    margin-left:4pt;
    margin-right:4pt;
    font-size: 16pt;
}

li {
    font-size: 16pt;
    width: 505pt;
    text-align: left;
    padding-bottom: 6pt;
}

u {
    border-bottom: 1px dotted #000;
    text-decoration: none;
    cursor: pointer;
}
    </style>
    <script language="JavaScript">
function next(slides){
    // show the next slide
    var first_slide = document.getElementById(slides + "_" + 1);
    for(var i = 1; i < 9; ++i)
    {
        var this_slide = document.getElementById(slides + "_" + i);
        var next_slide = document.getElementById(slides + "_" + (i+1));
        if(this_slide)
            if(this_slide.style.display == "block")
                {
                this_slide.style.display = "none";
                if(next_slide)
                    next_slide.style.display = "block";
                else
                    first_slide.style.display = "block";
                break;
                }
    }
    // name the button
    var button = document.getElementById(slides + "_button")
    for(var i = 1; i < 9; ++i)
    {
        var this_slide = document.getElementById(slides + "_" + i);
        var next_slide = document.getElementById(slides + "_" + (i+1));
        if (this_slide && !next_slide && this_slide.style.display == "block") {
            button.innerHTML = "Back to the 1-st step";
            break;
        }
        else
            button.innerHTML = "Next step";
    }
}

function draw_results(){
    var d = document.getElementById("results");
    var d_context = d.getContext("2d");
    d_context.font = "16px sans-serif";
    // background
    d_context.fillStyle="#eeeeee";
	d_context.fillRect(0, 0, 702, 500);

	var x = 0.0;
	var y = 0.0;
	// C metaprogramming
	x = 0.5;
	y = 1.5;
	d_context.fillStyle="#BB0022";
	d_context.fillText("70 ms. C with tricks", x + 4, y + 16);
	d_context.beginPath();
	d_context.strokeStyle="#BB0022";
	d_context.moveTo(x, y);
	d_context.lineTo(x+233, y);
	d_context.lineWidth=2;
	d_context.stroke();
	d_context.closePath();

	// C++ metaprogramming
	x = 234.5;
	y = 499.5 - Math.floor(499 * 60/ 70);
	d_context.fillStyle="#882200";
	d_context.fillText("60 ms. C++ with a trick", x + 4, y - 8);
	d_context.beginPath();
	d_context.strokeStyle="#882200";
	d_context.moveTo(x, y);
	d_context.lineTo(x+233, y);
	d_context.lineWidth=2;
	d_context.stroke();
	d_context.closePath();

	// Python + LLVM
	x = 498.5;
	y = 499.5 - Math.floor(499 * 55 / 70);
	d_context.fillStyle="#668811";
	d_context.fillText("55 ms. Python + LLVM", x + 4, y - 8);
	d_context.beginPath();
	d_context.strokeStyle="#446600";
	d_context.moveTo(x, y);
	d_context.lineTo(x+233, y);
	d_context.lineWidth=2;
	d_context.stroke();
	d_context.closePath();
}

function init_results(){
    draw_results();
}

function colorized(text) {
    const separators = ['def ', ' for ', ' else', ' if ', ' break', 'return', 'class ', ' in ', 'global ',
        '\n', ' ', '\t', '.', ',', ':', '=', '[', ']', '(', ')', '+', '-', '*', '/'];
    const quotes = ['\'', '"'];
    const comments = [['#', '\n']];

    function painted_in(line, color) {
        return line.length == 0 ? "" : "<span style=\"color:#" + color + "\">" + line + "</span>";
    }

    function colorized(token) {
        var code_sum = 0;
        for(var i = 0; i < token.length; ++i)
            code_sum += ([1, 7, 11, 13][i % 4] * token.charCodeAt(i));
        var zero_channel = code_sum % 3;
        var color = '' + (zero_channel == 0 ? '3' : '') + (1 + (code_sum % 5) * 2)
            + (zero_channel == 1 ? '3' : '') + (4 + (code_sum % 2) * 5)
            + (zero_channel == 2 ? '3' : '');
        return painted_in(token, color);
    }

    function separated(line, i) {
        if(i == separators.length)
            return colorized(line);
        return line.split(separators[i]).map(function(subline) {
            return separated(subline, i + 1);}).join(separators[i]);
    }

    function unquoted(line, i) {
        if(i == quotes.length)
            return separated(line, 0);
        var chunk_no = 0;
        return line.split('\\' + quotes[i]).join('\0').split(quotes[i]).map(function (chunk) {
            return chunk.split('\0').join('\\' + quotes[i]);}).map(function (chunk) {
                return ++chunk_no % 2  == 1 ? unquoted(chunk, i + 1) : painted_in(quotes[i] + chunk + quotes[i], "555");}).join('');
    }

    function uncommented(line, i) {
        if(i == comments.length)
            return unquoted(line, 0);
        var chunks = line.split(comments[i][0]);
        return uncommented(chunks[0], i + 1) + chunks.slice(1).map( function(chunk) {
            var in_out_comment = chunk.split(comments[i][1]);
            return painted_in(comments[i][0] + in_out_comment[0] + (in_out_comment.length > 1 ? comments[i][1] : ''), "555")
                + uncommented(in_out_comment.slice(1).join(comments[i][1]), i + 1);}).join('');
    }

    return uncommented(text, 0);
}
    </script>
  </head>
  <body>
    <center>
    <h1>
Outperforming everything with anything
<br>
<sub>Python? Sure, why not?</sub>
    </h1>
    <p>
This continues <a href="https://wordsandbuttons.online/outperforming_lapack_with_c_metaprogramming.html">Outperforming LAPACK with C metaprogramming</a>, and <a href="https://wordsandbuttons.online/vastly_outperforming_lapack_with_cpp_metaprogramming.html"> Vastly outperforming LAPACK with C++ metaprogramming</a>. These two posts describe language tricks to make compilers generate highly-performant code for you. But do you need compilers at all?
    </p>
    <p>
The alternative would be writing programs in plain assembly. Although the horrors of it are vastly exaggerated, this approach has two major flaws.
    </p>
    <ol>
    <li>
Assembly code is not portable.
    </li>
    <li>
Although it became much easier with modern tools, assembly programming still requires a lot of tedious work.
    </li>
    </ol>
    <p>
Thankfully, we all live in the XXI century, and both of these problems have already been addressed.
    </p>
    <p>
The solution to the first one would be <a href="https://en.wikipedia.org/wiki/LLVM">LLVM</a>. Initially, it meant “Low Level Virtual Machine” and that is exactly what we want to ensure portability. Simply put, it takes some code written in very low-level hardware agnostic language and returns some highly optimized native code for the specific hardware platform. With LLVM we have both the power of low-level programming and the automation of hardware-oriented micro-optimizations.
    </p>
    <p>
And the solution to the second problem is any “scripting” language you want. Scheme, Python, Perl, even bash or AWK will do. They are all meant to eliminate tedious work. Everything you use daily for automation you can use to generate highly-performant code.
    </p>
    <h2>
The plan
    </h2>
    <p>
Let's repeat the same experiment I did with C and C++ in the posts from before. Let's generate a fully inlined fully unrolled solution and embed it into the benchmarking code. The plan then is as follows.
    <ol>
    <li>
Use Clang to generate LLVM intermediate code for the benchmark that is supposed to measure yet non-existent function named <i>solve_5</i>
    </li>
    <li>
Make Python generate a linear solver code in LLVM.
    </li>
    <li>
Hijack a benchmark with a Python script replacing <i>solve_5</i> call with the generated solver.
    </li>
    <li>
Use the LLVM static compiler to turn the intermediate code into the machine code.
    </li>
    <li>
Use the GNU assembler and the Clang's linker to make the machine code into an executable binary.
    </li>
    </ol>
    <p>
That's how it looks in a Makefile:
    </p>
    <table><tr>
    <td>
    <pre>
all: generate_llvm generate_s generate_elf test
.PHONY: generate_llvm
generate_llvm:
  <b>clang</b> benchmark.c -march=native -S -emit-llvm -o benchmark.bc
  <b>python</b> substitute_solver_call.py benchmark.bc
.PHONY: generate_s
generate_s:
  <b>llc</b> -O2 benchmark.bc -o benchmark.s
.PHONY: generate_elf
generate_elf:
  <b>as</b> benchmark.s -o benchmark.o
  <b>clang</b> -o benchmark benchmark.o
    </pre>
    </td></tr>
    </table>
    <h2>
The Python part
    </h2>
    <p>
We need a linear solver in Python just like we had with C and C++. Here it is:
    </p>
    <table><tr>
    <td>
    <pre id="code_1">
# this generates n-solver in LLVM code with LLVMCode objects.
# No LLVM stuff yet, just completely Pythonic solution
def solve_linear_system(a_array, b_array, x_array, n_value):
  def a(i, j, n):
    if n == n_value:
      return a_array[i * n_value + j]
    return a(i, j, n+1)*a(n, n, n+1) - a(i, n, n+1)*a(n, j, n+1)

  def b(i, n):
    if n == n_value:
      return b_array[i]
    return a(n, n, n+1)*b(i, n+1) - a(i, n, n+1)*b(n, n+1)

  def x(i):
    d = b(i,i+1)
    for j in range(i):
      d -= a(i, j, i+1) * x_array[j]
    return d / a(i, i, i+1)

  for k in range(n_value):
    x_array[k] = x(k)

return x_array
    </pre>
    </td>
    </tr></table>
    <p>
When we run this on numbers, we have numbers. But we want the code. So let's make an object that pretends to be numbers only to spy on the algorithm. The object that writes down every operation the algorithm wants it to perform in ready to assemble LLVM intermediate language.
    </p>
    <table><tr>
    <td>
    <pre id="code_2">
# this is basically the whole LLVM layer
I = 0
STACK = []

class LLVMCode:
  # the only constructor for now is by double* instruction
  def __init__(self, io, code = ''):
    self.io = io
    self.code = code
  def __getitem__(self, i):
    global I, STACK
    copy_code = "%" + str(I+1)
    copy_code += " = getelementptr inbounds double, double* "
    copy_code += self.io +", i64 " + str(i) + "\n"
    copy_code += "%" + str(I+2)
    copy_code += " = load double, double* %" + str(I+1)
    copy_code += ", align 8\n"
    I += 2
    STACK += [I]
    return LLVMCode(self.io, copy_code)
  def __setitem__(self, i, other_llvcode):
    global I, STACK
    self.code += other_llvcode.code
    self.code += "%" + str(I+1)
    self.code += " = getelementptr inbounds double, double* "
    self.code += self.io +", i64 " + str(i) + "\n"
    self.code += "store double %" + str(I)
    self.code += ", double* %" + str(I+1) + ", align 8\n"
    I += 1
    STACK = STACK[:-1]
    return self
  def general_arithmetics(self, operator, other_llvcode):
    global I, STACK
    self.code += other_llvcode.code;
    self.code += "%" + str(I+1) + " = f" + operator
    self.code += " double %" + str(STACK[-2]) + ", %"
    self.code += str(STACK[-1]) + "\n";
    I += 1
    STACK = STACK[:-2] + [I]
    return self
  def __add__(self, other_llvcode):
    return self.general_arithmetics('add', other_llvcode)
  def __sub__(self, other_llvcode):
    return self.general_arithmetics('sub', other_llvcode)
  def __mul__(self, other_llvcode):
    return self.general_arithmetics('mul', other_llvcode)
  def __div__(self, other_llvcode):
    return self.general_arithmetics('div', other_llvcode)
    </pre>
    </td>
    </tr></table>
    <p>
Now when we run the solver with this kind of objects, we get a fully functional linear solver written in LLVM intermediate language. Then we put it into the benchmark code to see how fast it is.
    </p>
    <p>
Instruction in LLVM are numbered and we want to preserve this enumeration, so the function that inserts our code into our benchmark is not trivial. But it's not very complicated either.
    </p>
    <table><tr>
    <td>
    <pre id="code_3">
# this replaces the function call
# and updates all the instructions' indices
def replace_call(text, line, params):
  global I, STACK
  # '%12 ' -> 12
  I = int(''.join(
    [xi for xi in params[2] if xi.isdigit()]
    ))
  first_instruction_to_replace = I + 1
  STACK = []
  replacement = solve_linear_system(
    LLVMCode(params[0]),
    LLVMCode(params[1]),
    LLVMCode(params[2]), 5).code
  delta_instruction = I - first_instruction_to_replace + 1
  for i in xrange(first_instruction_to_replace, sys.maxint):
    not_found = sum(
      [text.find('%' + str(i) + c) == -1
        for c in POSSIBLE_CHARS_NUMBER_FOLLOWS_WITH]
      )
    if not_found == 4:
      # the last instruction has already been substituted
      break
    new_i = i + delta_instruction
    for c in POSSIBLE_CHARS_NUMBER_FOLLOWS_WITH:
      # substitute instruction number
      text = text.replace('%' + str(i) + c, '%' + str(new_i) + c)
return text.replace(line, replacement)
    </pre>
    </td>
    </tr></table>
    <p>
The whole piece of code that implements the solver, provides the Python-to-LLVM layer, and does the code insertion is only 100 lines long! You can see it in <a href="https://github.com/akalenuk/wordsandbuttons/blob/master/exp/python_to_llvm/exp_embed_on_call/substitute_solver_call.py">one piece on GitHub</a>.
    </p>
    <h2>
The benchmark
    </h2>
    <p>
The benchmark itself is in C. When we run the Makefile, its call for <i>solve_5</i> gets replaced by the LLVM code generated from Python by Python.
    </p>
    <table><tr>
    <td>
    <pre><span id="slides_recursive_1" style="display:block"><div style="color:#994466"><b>Step 1. Benchmark C source code</b></div>
#include "stdio.h"

<b>extern void solve_5(double* a, double* b, double* x);</b> // fake

int main() {
    double sum_x[5] = {0., 0., 0., 0., 0.};
    for(int i = 0; i &lt; 1000000; ++i) {
        double a[5*5] = {
            6.80, -6.05, -0.45,  8.32, -9.67,
           -2.11, -3.30,  2.58,  2.71, -5.14,
            5.66,  5.36, -2.70,  4.35, -7.26,
            5.97, -4.44,  0.27, -7.17,  6.08,
            8.23,  1.08,  9.04,  2.14, -6.87
        };
        double b[5] = {
            4.02,  6.19, -8.22, -7.57, -3.03,
        };
        double x[5];

        <b>solve_5(a, b, x);</b> // this will get replaced later

        for(int j = 0; j &lt; 5; ++j){
            sum_x[j] += x[j];
        }
    }
    printf("%f, %f, %f, %f, %f\n",
        sum_x[0], sum_x[1], sum_x[2], sum_x[3], sum_x[4]);
    return 0;
}

</span><span id="slides_recursive_2" style="display:none"><div style="color:#992244"><b>Step 2. LLVM assembly language</b></div>
... 27 lines before...
<span style="font-size:10pt;">; &lt;label&gt;:6                                       ; preds = %3
  %7 = bitcast [25 x double]* %a to i8*
  call void @llvm.memcpy.p0i8.p0i8.i32
    (i8* %7, i8* bitcast ([25 x double]* @main.a to i8*), i32 200, i32 8, i1 false)
  %8 = bitcast [5 x double]* %b to i8*
  call void @llvm.memset.p0i8.i32(i8* %8, i8 0, i32 40, i32 8, i1 false)
  %9 = bitcast i8* %8 to [5 x double]*
  %10 = getelementptr [5 x double], [5 x double]* %9, i32 0, i32 0
  store double 4.020000e+00, double* %10
  %11 = getelementptr [5 x double], [5 x double]* %9, i32 0, i32 1
  store double 6.190000e+00, double* %11
  %12 = getelementptr [5 x double], [5 x double]* %9, i32 0, i32 2
  store double -8.220000e+00, double* %12
  %13 = getelementptr [5 x double], [5 x double]* %9, i32 0, i32 3
  store double -7.570000e+00, double* %13
  %14 = getelementptr [5 x double], [5 x double]* %9, i32 0, i32 4
  store double -3.030000e+00, double* %14
  %15 = getelementptr inbounds [25 x double], [25 x double]* %a, i32 0, i32 0
  %16 = getelementptr inbounds [5 x double], [5 x double]* %b, i32 0, i32 0
  %17 = getelementptr inbounds [5 x double], [5 x double]* %x, i32 0, i32 0
  <b>call void @solve_5(double* %15, double* %16, double* %17) ; to replace</b>
  store i32 0, i32* %j, align 4
  br label <b>%18 ; to update</b>

; &lt;label&gt;:18                                      ; preds = <b>%29</b>, <b>%6</b>
  <b>%19</b> = load i32, i32* %j, align 4
  <b>%20</b> = icmp slt i32 <b>%19</b>, 5
  br i1 <b>%20</b>, label <b>%21</b>, label <b>%32</b></span>
... 58 lines after... </span><span id="slides_recursive_3" style="display:none"><div style="color:#881122"><b>Step 3. LLVM after the call replacement</b></div>
... 44 lines before ...
<span style="font-size:10pt;">  %15 = getelementptr inbounds [25 x double], [25 x double]* %a, i32 0, i32 0
  %16 = getelementptr inbounds [5 x double], [5 x double]* %b, i32 0, i32 0
  %17 = getelementptr inbounds [5 x double], [5 x double]* %x, i32 0, i32 0
<b>%18 = getelementptr inbounds double, double* %15, i64 6  ; generated
%19 = load double, double* %18, align 8                  ; by
%20 = getelementptr inbounds double, double* %15, i64 24 ; the
%21 = load double, double* %20, align 8                  ; Python
%22 = fmul double %19, %21                               ; script</b>

</span>... 2407 more lines of auto-generated code ...<span style="font-size:10pt;">

<b>%2422 = getelementptr inbounds double, double* %17, i64 3
%2423 = load double, double* %2422, align 8
%2424 = fmul double %2421, %2423
%2425 = fsub double %2419, %2424
%2426 = getelementptr inbounds double, double* %15, i64 24
%2427 = load double, double* %2426, align 8
%2428 = fdiv double %2425, %2427
%2429 = getelementptr inbounds double, double* %17, i64 4
store double %2428, double* %2429, align 8</b>

  store i32 0, i32* %j, align 4
  br label <b>%2430  ; instructions updated by the same script</b>

; <label>:18                                      ; preds = %2441, %6
  <b>%2431</b> = load i32, i32* %j, align 4
  <b>%2432</b> = icmp slt i32 <b>%2431</b>, 5
  br i1 <b>%2432</b>, label <b>%2433</b>, label <b>%2444</b>
</span>... still 58 lines after...</span><span id="slides_recursive_4" style="display:none"><div style="color:#881122"><b>Step 4. Native optimized assembly</b></div>
... 139 lines of assembly ...
	vmovsd	352(%esp), %xmm0        # xmm0 = mem[0],zero
	vmulsd	256(%esp), %xmm2, %xmm6
	vmovsd	.LCPI0_0, %xmm4         # xmm4 = mem[0],zero
	vmulsd	%xmm4, %xmm0, %xmm7
	vsubsd	%xmm7, %xmm6, %xmm6
	vmulsd	128(%esp), %xmm0, %xmm5 # 8-byte Folded Reload
	vmovapd	%xmm0, %xmm3
	vmulsd	344(%esp), %xmm2, %xmm7
	vsubsd	%xmm5, %xmm7, %xmm1
	vmovsd	%xmm1, 128(%esp)        # 8-byte Spill
	vmulsd	280(%esp), %xmm2, %xmm7
	vmulsd	192(%esp), %xmm4, %xmm5 # 8-byte Folded Reload
	vsubsd	%xmm5, %xmm7, %xmm7
	vmovsd	%xmm7, 120(%esp)        # 8-byte Spill
	vmovsd	104(%esp), %xmm0        # 8-byte Reload

	vmulsd	%xmm6, %xmm0, %xmm5
	vmulsd	%xmm7, %xmm1, %xmm6
	vsubsd	%xmm6, %xmm5, %xmm5
	vmovsd	%xmm5, 64(%esp)         # 8-byte Spill
	vmovapd	%xmm3, %xmm7
	vmulsd	88(%esp), %xmm7, %xmm3  # 8-byte Folded Reload
	vmulsd	336(%esp), %xmm2, %xmm6
	vsubsd	%xmm3, %xmm6, %xmm3
	vmulsd	%xmm0, %xmm3, %xmm3
	vmulsd	80(%esp), %xmm1, %xmm6  # 8-byte Folded Reload
	vsubsd	%xmm6, %xmm3, %xmm1
	vmovsd	%xmm1, 88(%esp)         # 8-byte Spill
... only 400 more lines of assembly ...</span></pre>
    </td>
    </td></tr></table>
    <p style="text-align:right">
    <button type="button" id="slides_recursive_button" onclick="next('slides_recursive')">Next step</button>
    </p>
    <p>
The most noteworthy is how the ultra-verbose intermediate code generated by the Python script turns into some very compact and very effective code for the hardware. It is highly super-scalarized too. But is it good enough to compete with C and C++ solutions?
    </p>
    <p>
Here are some approximate numbers for the three cases: C with tricks, C++ with a trick, and Python with LLVM.
    </p>
    <ol>
    <li>
The tricks for C don't quite work for Clang, so GCC version is measured. It runs for roughly 70 ms on average.
    </li>
    <li>
The C++ version was built with Clang and it runs for 60 ms.
    </li>
    <li>
<b>The Python version, the one described here, runs only for 55 ms.</b>
    </li>
    </ol>
    <canvas id="results" width=700 height=500></canvas>
    <script language="JavaScript">
    init_results();
    document.getElementById("code_1").innerHTML = colorized(document.getElementById("code_1").innerHTML);
    document.getElementById("code_2").innerHTML = colorized(document.getElementById("code_2").innerHTML);
    document.getElementById("code_3").innerHTML = colorized(document.getElementById("code_3").innerHTML);
    </script>
    <p>
Of course, this speed-up is not something you would kill for. But it shows that you can write programs in Python that outperform their counterparts written in C or C++. You don't have to learn some special language to create high-performant applications or libraries.
    </p>
    <h2>
Conclusion
    </h2>
    <p>
I think that the dichotomy between fast compiling languages and slow scripting languages is a bluff. Native code generation may very well be not a core feature but something like a pluggable option. Like a library or an embedded language. Like <a href="http://numba.pydata.org/numba-doc/latest/user/5minguide.html">Numba</a> for Python or <a href="http://terralang.org/">Terra</a> for Lua. Think about the benefits: you can do your research and rapid prototyping in one language, and then generate highly-performant code... in the same language.
    </p>
    <p>
High-performance computing has no reason to remain a privilege of compiling languages. A compiler is just a soft machine for code generation. You can generate code in any language you want. I&nbsp;believe you can teach Matlab to generate ultra-fast LLVM code if you want to.
    </p>
    <br>
    <p style="font-family: sans-serif; font-size: 14pt;">
All the measurements conducted on Intel(R) Core(TM) i7-7700HQ CPU @ 2.80GHz, the code is compiled with clang version 3.8.0-2ubuntu4 and g++ 5.4.0 with -march=native -O2. The source code for the benchmark is <a href="https://github.com/akalenuk/wordsandbuttons/tree/master/exp/python_to_llvm">available on Github</a>.
    </p>

    <table class="footer" style="width: 555pt; padding: 64pt 0pt 32pt 0pt; background-color: transparent; font-family: sans-serif; font-size: 16pt; font-style: normal;">
	<tr>
	<td class="footer" style="vertical-align: middle; text-align: left; width: 64px; padding: 0; margin: 0; border: 0;">
		<a href="index.html"><img src="favicon.ico"></a> 
	</td>
	<td class="footer" style="vertical-align: middle; text-align: left; width: 200pt; padding: 0; margin: 0; border: 0;">
		&nbsp;&larr; there's more.
	</td>
	<td class="footer" style="vertical-align: middle; text-align: right; width: 300pt; padding: 0; margin: 0; border: 0;">
		+
		<a href="https://github.com/akalenuk/wordsandbuttons">Github</a> &
		<a href="https://twitter.com/wordsandbuttons">Twitter</a> &
		<a href="https://wordsandbuttons.online/rss"><span style="letter-spacing: 1pt;">RSS</span></a>
	</td>
	</tr>
	</table>
    </center>
  </body>
</html>
