<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <title>If I were to invent a programming language for the 21st century</title>
    <link rel="shortcut icon" type="image/x-icon" href="favicon.ico" />
    <style>
body{
    margin: 0 0 0 0;
}

a{
    text-decoration: none;
}

h1 {
    padding-top: 32pt;
    font-size: 24pt;
    width: 600pt;
    text-align: left;
}

h2 {
    padding-top: 16pt;
    font-size: 20pt;
    width: 555pt;
    text-align: left;
}

p {
    font-size: 16pt;
    width: 505pt;
    text-align: left;
}

pre {
    margin: 0 0 0 0;
    padding-top: 12pt;
    padding-left: 12pt;
    padding-right: 12pt;
    padding-bottom: 12pt;
    font-size: 12pt;
    text-align: left;
    width: 300pt;
}

table {
    border-width: 0pt;
}

td {
    vertical-align: top;
    padding: 6pt 12pt 6pt 12pt;
    font-size: 16pt;
    border: 1px solid black;
    width: 505pt;
}

button{
    width: 128pt;
    height: 32pt;
    margin-left: 8pt;
    margin-right: 8pt;
    margin-top: 4pt;
    margin-bottom: 4pt;
    font-size: 16pt;
}

u {
    border-bottom: 1px dotted #000;
    text-decoration: none;
    cursor: pointer;
}

.comment {
    font-size: 12pt;
    text-align: right;
    font-family: sans-serif;
    padding-bottom: 24pt;
}
    </style>
    <script language="JavaScript">
function show(n){
    document.getElementById("shown_" + n).style.display = "none";
    document.getElementById("hidden_" + n).style.display = "inline";
}

function hide(n){
    document.getElementById("shown_" + n).style.display = "inline";
    document.getElementById("hidden_" + n).style.display = "none";
}
    </script>
  </head>
  <body>
    <center>
    <h1>
If I were to invent a programming language<br> for the 21st century
    </h1>
    <p>
Quite a few programming languages were already invented in the 21st century. Swift, Kotlin, and Go are probably among the most popular. However, the distinct feature of the 21st-century language design is the absence of any distinct features in the languages themselves. The best thing about any of these is that you can spend a weekend and claim to learn a shiny new thing without actually learning anything new. They don’t have anything new in them at all; they are all made by the “something done right” formula, this something being Objective-C, Java or C.
    </p>
    <p>
While “not being new” is indeed a valuable trait in its own right, the question arises. Are they indeed the languages for the 21st century, or are they merely the reflection on the 20th-century bad programming habits?
    </p>
    <p>
If I were to invent a language, I wouldn’t try to fix the past. I would try to invent a thing that not only works well in the reality of the modern world but can also evolve properly and stand the test of time. If this requires radical design decisions, so be it.
    </p>
    <h2>
1. Down with the syntax!
    </h2>
    <p>
Modern languages syntaxes reflect the freedom of chalk and blackboard put into the shackles of ASCII. While some elements of notation like arithmetical signs and brackets are more or less idiomatic, some are just made up for no reason at all apart from saving the effort of pressing teletype buttons.
    </p>
    <p>
Typing is not an issue anymore. We are not obliged to play guess with our syntax. Things like this <i>(($:@(<#[), (=#[), $:@(>#[)) ({~ ?@#)) ^: (1<#)</i> are indeed concise and expressive. And also fun to write. <span id="shown_sidenote_1" onclick="show('sidenote_1')"><u>*</u></span><span id="hidden_sidenote_1" style="display:none; color:#555555;">This line, by the way, is an <a href="https://en.wikipedia.org/wiki/J_(programming_language)#Examples">actual piece of code</a> in <a href="https://en.wikipedia.org/wiki/J_(programming_language)">an actual language</a>.<span onclick="hide('sidenote_1')"><u>&larr;</u></span></span>
    </p>
    <p>
But they do not help readability and, what’s even more critical, googleability and stackoverflowability.
    </p>
    <p>
The same goes for cryptic function names, return code conventions, and attributes with obscure meaning. They served us well in the past, saving our punch-card space, now they deserve retirement.
    </p>
    <p>
Ultimately this:
    </p>
    <table><tr>
    <td>
    <pre>
<b><span style="color:#4d2508">FILE</span> * <span style="color:#08204d">test_file</span> = <span style="color:#4d0813">fopen</span>(<span style="color:#144d08">“/tmp/test.txt”</span>, <span style="color:#144d08">“w+”</span>);</b>
    </pre>
    </td>
    </td></tr></table>
    <p>
Should become something like this:
    </p>
    <table><tr>
    <td>
    <pre>
<b><span style="color:#4d0813">create file</span> <span style="color:#144d08">/tmp/test.txt</span> <span style="color:#4d0813">for</span> <span style="color:#4d2508">input</span> <span style="color:#4d0813">and</span> <span style="color:#4d2508">output</span> <span style="color:#4d0813">as</span> <span style="color:#08204d">test_file</a></b>
    </pre>
    </td>
    </td></tr></table>
    <p>
We don’t need all that brackets, quotes, asterisks, and semicolons (unless they really help us to express things better). Syntax highlighting should work instead of syntax notation just fine.
    </p>
    <p>
Things that are cheap in the 21st century: parsing time, computer memory, online search. Things that are not: development time, programmer’s memory, effort spent online learning the language specifics. This type of writing should facilitate the usage of cheaper things over the more expensive ones.
    </p>
    <h2>
2. Down with the native types!
    </h2>
    <p>
You probably know this as one of the <a href="https://www.destroyallsoftware.com/talks/wat">JavaScript wats</a>.
    </p>
    <table><tr>
    <td>
    <pre>
<b>&gt; 10.8 <span style="color:#4d0813">/</span> 100
<span style="color:#08204d">0.10800000000000001</span></b>
    </pre>
    </td>
    </td></tr></table>
    <p>
It isn’t, of course, JavaScript specific. In fact, it is not a wat at all, it is a perfectly correct behavior backed by the well-respected IEEE 754 standard. It’s just how floating point numbers are implemented in almost any architecture. And it’s actually not that bad considering we are trying to squeeze an infinite amount of real numbers into 32, 64 or even 256 bits.
    </p>
    <p>
What mathematicians consider impossible, engineers do by trading off sanity for possibility. IEEE floating point numbers are not, in fact, numbers at all. Maths requires real numbers' addition to have associativity. Floats and doubles do not always hold this property. Maths requires real numbers to include all the integers. This is not true even for the same sized <i>float</i> and <i>uint32_t</i>. Maths requires real numbers to have a zero element. Well, at least in this regard IEEE standard exceed the expectations, as floating point numbers have two zero elements instead of one.
    </p>
    <p>
And it’s not only about floating point numbers. Native integers are not much better. Do you know what happens when you add up two 16-bit numbers like that?
    </p>
    <table><tr>
    <td>
    <pre>
<b>0xFFFF <span style="color:#4d0813">+</span> 0x0001</b>
    </pre>
    </td>
    </td></tr></table>
    <p>
Well, nobody knows actually. Intuition tells, that the overflowed number should be <i>0x0000</i>. But this is not specified by any worldwide standard; it’s just how it usually goes with C and with x86-family processors. It may also result in <i>0xFFFF</i>, or trigger an interrupt, or store some special bit in a special place signaling that the overflow happened.
    </p>
    <p>
It is not specified at all. It differs. While floating point numbers are just standard insane, these are entirely unpredictable.
    </p>
    <p>
What I would propose for numeric computations instead is fixed point arbitrary sized data types with standard defined behavior on underflow, overflow, and precision loss. Something like this:
    </p>
    <table><tr>
    <td>
    <pre>
<b>1.000 <span style="color:#4d0813">/</span> 3.000 <span style="color:#4d0813">=</span> 0.333
0001 <span style="color:#4d0813">+</span> 9999 <span style="color:#4d0813">=</span> <span style="color:#4d2508">overflowed</span> 9999
0.001 <span style="color:#4d0813">/</span> 2 <span style="color:#4d0813">=</span> <span style="color:#4d2508">underflowed</span> 0</b>
    </pre>
    </td>
    </td></tr></table>
    <p>
Of course, you don’t have to actually write all the trailing zeros, they should be implied by the data type definition. But you should be able to select your maximum and minimum bounds for the type yourself, not just rely on the current processor's architecture.
    </p>
    <p>
Wouldn’t it work much slower then? Yes, it would. But realistically, how often do you have to program high-performance computations? I suppose, unless you work in a narrow field of research and engineering that requires exactly that, not very often. And if you do, you have to use specialized hardware and compilers anyway. I’ll just presume, a typical 21st-century programmer don't have to solve differential equations very often.
    </p>
    <p>
That being said, shouldn’t fast, complex and unpredictable native types from the past be an option and not the default?
    </p>
    <h2>
3. Down with the metalanguaging!
    </h2>
    <p>
There are brilliant wonderful languages designed not to do the task, but to create languages that do the task. Racket, Rebol, and Forth to name a few. I love them all, they are a pure delight to play with. But as you might guess, being fun is not exactly what makes a language universally popular.
    </p>
    <p>
Language leverage, the ability to create new sub-languages for the task, is a great power, and it pays vastly to have it when you work in research all on your own. Unfortunately, if you write code for other people to understand, you have to teach them your language along with the code. And that’s when it gets ugly.
    </p>
    <p>
People are generally interested in getting things done, not learning the language they’d have to forget anyway after the things are done. For other people, learning your language is just an effort that would hardly pay off. Learning something common and standardized, however, is an investment for life. Therefore, people will rather reinvent your language themselves than learn it. And there you go: countless dialects for the single domain; people arguing about aesthetics, ideology, architecture and all the things that are irrelevant; million lines of code being written just to be forgotten in months.
    </p>
    <p>
Lisp guys went through all of that in the 80s. They figured out that the more of the practical part of a language is standardized — the better. And they came up with Common Lisp.
    </p>
    <p>
And it’s huge. The INCITS 226–1994 standard consists of 1153 pages. This was only beaten by C++ ISO/IEC 14882:2011 standard with 1338 pages some 17 years after. C++ has to drag a bag of heritage though, it was not always that big. Common Lisp was created huge from the scratch.
    </p>
    <p>
A programming language should not be that huge. Not at all. It’s just that it should have a decent standard library filled with all the goodies so people wouldn't have to reinvent them.
    </p>
    <p>
It is difficult to balance hugeness and applicability. We had to learn this with C++ the hard way. I think, to balance things properly, the language for the 21st century should be more domain specific than not. Since business applications are currently the biggest mess, perhaps it should address that and not some game development or web-design.
    </p>
    <h2>
So…
    </h2>
    <p>
The language for the 21st century should be business oriented, English-like and not dependent on native types.
    </p>
    <p>
The most exciting thing, we already have the language exactly like this! What do you think it is?
    </p>

    <p>
    <div id="shown_hidden">
        <button type="button" onclick="show('wrong'); show('hidden');">Kotlin</button>
        <button type="button" onclick="show('wrong'); show('hidden');">Haskell</button>
        <button type="button" onclick="show('wrong'); show('hidden');">Go</button>
        <br>
        <button type="button" onclick="show('wrong'); show('hidden');">Rust</button>
        <button type="button" onclick="show('wrong'); show('hidden');">Swift</button>
        <button type="button" onclick="show('wrong'); show('hidden');">Julia</button>
        <br>
        <button type="button" onclick="show('wrong'); show('hidden');">Fortran</button>
        <button type="button" onclick="show('right'); show('hidden');">COBOL</button>
        <button type="button" onclick="show('wrong'); show('hidden');">Assembly</button>
    <p class="comment">
&uarr; these are all clickable, yes.
    </p>
    </div>
    <div id="shown_right"></div>
    <div id="hidden_right" style="display:none;">
        <p>
Yes, it is COBOL. One of the first high-level languages mostly forgotten now but not forgiven.
        </p>
    </div>
    <div id="shown_wrong"></div>
    <div id="hidden_wrong" style="display:none;">
        <p>
Nope. It's COBOL. One of the first high-level languages mostly forgotten now but not forgiven.
        </p>
    </div>
    </p>

    <div id="hidden_hidden" style="display:none;">
        <p>
I have to confess, I deliberately described ancient COBOL's features as ultra-modern and super-promising to show you one thing. Language features don’t write the code. You do.
        </p>
        <p>
It’s naïve to think that the language is responsible for the quality of code and that by adding some bells and whistles (or removing some bells and whistles), we can automatically make everything better. We were not happy with Fortran and COBOL, so we invented C++ and Java only to be unhappy with them too in some 20–30 years.
        </p>
        <p>
I feel like the core issue here is in the domain of sociology and psychology, and not the programming. Are we really unhappy with the languages? Aren’t we unhappy with the environment in general? Windows is vulnerable, Visual Studio is sluggish, and Vim is impossible to quit from. That’s what really disappointing, not the creative process per se.
        </p>
        <p>
But we have to blame something. Being software engineers partially responsible for the world of crappy software, we wouldn’t blame ourselves, would we? So let’s blame the tools instead! Let us reinvent COBOL again and again until one day the sun shines, and birds are singing, and it takes 2 seconds for Windows to boot.
        </p>
        <p>
Probably not going to happen.
        </p>
        <p>
So if I were to invent a programming language for the 21st century, I would reinvent being responsible instead. I would reinvent learning your tools; I would reinvent being attentive to essential details and being merciless to accidental complexity. Unlike the languages that come and go with the fashion, the things that matter do deserve constant reinvention.
        </p>
    </div>

    <table class="footer" style="width: 555pt; padding: 64pt 0pt 32pt 0pt; background-color: transparent; font-family: sans-serif; font-size: 16pt; font-style: normal;">
    <tr>
    <td class="footer" style="vertical-align: middle; text-align: left; width: 64px; padding: 0; margin: 0; border: 0;">
        <a href="index.html"><img src="favicon.ico"></a>
    </td>
    <td class="footer" style="vertical-align: middle; text-align: left; width: 200pt; padding: 0; margin: 0; border: 0;">
        &nbsp;&larr; there's more.
    </td>
    <td class="footer" style="vertical-align: middle; text-align: right; width: 300pt; padding: 0; margin: 0; border: 0;">
        +
        <a href="https://github.com/akalenuk/wordsandbuttons">Github</a> &
        <a href="https://twitter.com/wordsandbuttons">Twitter</a> &
        <a href="https://news.ycombinator.com/from?site=wordsandbuttons.online">Hacker News</a>
    </td>
    </tr>
    </table>
    </center>
  </body>
</html>
